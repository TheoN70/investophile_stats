{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_data(assets: list, start: datetime.datetime, end: datetime.datetime, path=\"binance_1h\",step='1h',quote_asset=\"USDT\") -> None:\n",
    "    \"\"\"\n",
    "    Collects and saves historical market data for specified assets in CSV files.\n",
    "\n",
    "    Parameters:\n",
    "    - assets (list): List of asset symbols to collect data for.\n",
    "    - start (datetime.datetime): Start date and time for data collection.\n",
    "    - end (datetime.datetime): End date and time for data collection.\n",
    "    - path (str): Path to the directory where CSV files will be saved. Default is \"binance_1m\".\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # Loop through each asset and collect data\n",
    "    for asset in assets:\n",
    "        df = get_data(asset, start, end,step,quote_asset)\n",
    "        full_path = path + '/' + asset + '.csv'\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df = df[~df.index.duplicated(keep='first')]\n",
    "        df.to_csv(full_path)\n",
    "\n",
    "def get_data(asset: str, start: datetime.datetime, end: datetime.datetime, step: str, quote_asset:str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieves historical market data for a specific asset.\n",
    "\n",
    "    Parameters:\n",
    "    - asset (str): Symbol of the asset.\n",
    "    - start (datetime.datetime): Start date and time for data collection.\n",
    "    - end (datetime.datetime): End date and time for data collection.\n",
    "    - step (int): Time interval for data points.\n",
    "    - quote_asset (str): Quote asset symbol. Default is \"USDT\".\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing historical market data.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    limit = 1000\n",
    "    start_time = start\n",
    "\n",
    "    # Collect data in chunks of 'limit' hours until the end time is reached\n",
    "    while start_time < end + datetime.timedelta(hours=limit):\n",
    "        end_time = start_time + datetime.timedelta(hours=limit)\n",
    "        res += data_call(asset, quote_asset, step, start_time, end_time, limit)\n",
    "        start_time = end_time\n",
    "\n",
    "    # Collect remaining data until the specified end time\n",
    "    end_time = end\n",
    "    res += data_call(asset, quote_asset, step, start_time, end_time, limit)\n",
    "\n",
    "    return pd.DataFrame(data=res, columns=[\"Close\", \"Time\"]).set_index(\"Time\")\n",
    "\n",
    "def data_call(asset: str, quote_asset: str, step: int, start_time: datetime.datetime, end_time: datetime.datetime, limit: int) -> list:\n",
    "    \"\"\"\n",
    "    Makes API call to Binance to retrieve historical market data.\n",
    "\n",
    "    Parameters:\n",
    "    - asset (str): Symbol of the asset.\n",
    "    - quote_asset (str): Quote asset symbol.\n",
    "    - step (int): Time interval for data points.\n",
    "    - start_time (datetime.datetime): Start date and time for data collection.\n",
    "    - end_time (datetime.datetime): End date and time for data collection.\n",
    "    - limit (int): Maximum number of data points per API call.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of lists containing historical market data.\n",
    "    \"\"\"\n",
    "    url = 'https://api.binance.com/api/v3/klines?symbol=' + asset + quote_asset + '&interval=' + str(step) + '&startTime=' + str(int(start_time.timestamp())) + '000' + '&endTime=' + str(int(end_time.timestamp())) + '000&limit=' + str(limit)\n",
    "    data = requests.get(url).json()\n",
    "    return extract_data(data)\n",
    "\n",
    "def extract_data(data):\n",
    "    \"\"\"\n",
    "    Extracts relevant data from the API response.\n",
    "\n",
    "    Parameters:\n",
    "    - data: API response containing raw market data.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of lists containing relevant market data.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for obj in data:\n",
    "        date = datetime.datetime.fromtimestamp(int(str(obj[6])[:-3]) + 1)\n",
    "        close_price = obj[4]\n",
    "        res.append([close_price, date])\n",
    "    return res\n",
    "\n",
    "def load_data(assets: list, start: datetime.datetime, end: datetime.datetime, fields=\"Close\", path=\"binance_1h\"):\n",
    "    \"\"\"\n",
    "    Load historical market data from CSV files for specified assets and time range.\n",
    "\n",
    "    Parameters:\n",
    "    - assets (list): List of asset symbols to load data for.\n",
    "    - start (datetime.datetime): Start date and time for data loading.\n",
    "    - end (datetime.datetime): End date and time for data loading.\n",
    "    - fields (list): List of fields to include in the loaded data. Default is [\"Close\"].\n",
    "    - path (str): Path to the directory where CSV files are stored. Default is \"binance_1m\".\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing loaded historical market data for specified assets and fields.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    # Iterate through each asset and load data\n",
    "    for asset in assets:\n",
    "        # Read CSV file and set the \"Time\" column as the index\n",
    "        obj = pd.read_csv(path + '/' + asset + '.csv').set_index(\"Time\")\n",
    "\n",
    "        # Keep only specified fields\n",
    "        obj = obj[fields]\n",
    "        \n",
    "        # Convert the index to datetime format\n",
    "        obj.index = pd.to_datetime(obj.index)\n",
    "\n",
    "        # Filter data for the specified time range\n",
    "        obj = obj.loc[start:end]\n",
    "\n",
    "        # Drop any rows with missing values\n",
    "        obj = obj.dropna()\n",
    "\n",
    "        # Store the loaded data in the 'data' dictionary\n",
    "        data[asset] = obj\n",
    "\n",
    "    # Create a DataFrame from the 'data' dictionary\n",
    "    return pd.DataFrame(data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets = [\"BTC\",\"ETH\",\"BNB\",\"XRP\",\"SOL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start=datetime.datetime(2023, 1, 2 ,0, 0, 0, 0) \n",
    "end=datetime.datetime(2023, 3, 2 ,0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data\n",
    "collect_data(assets,start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC</th>\n",
       "      <th>ETH</th>\n",
       "      <th>BNB</th>\n",
       "      <th>XRP</th>\n",
       "      <th>SOL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-02 01:00:00</th>\n",
       "      <td>16616.75</td>\n",
       "      <td>1200.34</td>\n",
       "      <td>244.4</td>\n",
       "      <td>0.3387</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02 02:00:00</th>\n",
       "      <td>16588.35</td>\n",
       "      <td>1198.16</td>\n",
       "      <td>243.6</td>\n",
       "      <td>0.3366</td>\n",
       "      <td>9.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02 03:00:00</th>\n",
       "      <td>16565.04</td>\n",
       "      <td>1195.16</td>\n",
       "      <td>242.1</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>9.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02 04:00:00</th>\n",
       "      <td>16587.85</td>\n",
       "      <td>1196.79</td>\n",
       "      <td>242.4</td>\n",
       "      <td>0.3266</td>\n",
       "      <td>9.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02 05:00:00</th>\n",
       "      <td>16661.94</td>\n",
       "      <td>1201.94</td>\n",
       "      <td>243.9</td>\n",
       "      <td>0.3287</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01 20:00:00</th>\n",
       "      <td>23690.88</td>\n",
       "      <td>1655.01</td>\n",
       "      <td>302.3</td>\n",
       "      <td>0.3831</td>\n",
       "      <td>22.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01 21:00:00</th>\n",
       "      <td>23355.14</td>\n",
       "      <td>1634.79</td>\n",
       "      <td>300.9</td>\n",
       "      <td>0.3805</td>\n",
       "      <td>22.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01 22:00:00</th>\n",
       "      <td>23421.23</td>\n",
       "      <td>1642.54</td>\n",
       "      <td>301.6</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>22.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01 23:00:00</th>\n",
       "      <td>23553.73</td>\n",
       "      <td>1657.01</td>\n",
       "      <td>302.3</td>\n",
       "      <td>0.3828</td>\n",
       "      <td>22.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-02 00:00:00</th>\n",
       "      <td>23531.94</td>\n",
       "      <td>1656.53</td>\n",
       "      <td>302.0</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>22.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1416 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          BTC      ETH    BNB     XRP    SOL\n",
       "Time                                                        \n",
       "2023-01-02 01:00:00  16616.75  1200.34  244.4  0.3387   9.99\n",
       "2023-01-02 02:00:00  16588.35  1198.16  243.6  0.3366   9.91\n",
       "2023-01-02 03:00:00  16565.04  1195.16  242.1  0.3253   9.85\n",
       "2023-01-02 04:00:00  16587.85  1196.79  242.4  0.3266   9.92\n",
       "2023-01-02 05:00:00  16661.94  1201.94  243.9  0.3287   9.99\n",
       "...                       ...      ...    ...     ...    ...\n",
       "2023-03-01 20:00:00  23690.88  1655.01  302.3  0.3831  22.42\n",
       "2023-03-01 21:00:00  23355.14  1634.79  300.9  0.3805  22.15\n",
       "2023-03-01 22:00:00  23421.23  1642.54  301.6  0.3833  22.25\n",
       "2023-03-01 23:00:00  23553.73  1657.01  302.3  0.3828  22.45\n",
       "2023-03-02 00:00:00  23531.94  1656.53  302.0  0.3833  22.41\n",
       "\n",
       "[1416 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Local Data\n",
    "data = load_data(assets,start,end)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_array = np.array(data[\"BTC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_returns = np.diff(np.log(x_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002458992399343684"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = np.mean(log_returns)\n",
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3912831202046395e-05"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma2 = np.var(log_returns)\n",
    "sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the data\n",
    "x_array = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the logarithmic returns\n",
    "log_returns = np.diff(np.log(x_array),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Expected Value vector\n",
      "\n",
      " [2.45899240e-04 2.27646787e-04 1.49555329e-04 8.74227651e-05\n",
      " 5.70970103e-04]\n"
     ]
    }
   ],
   "source": [
    "# Compute the expected values vector\n",
    "mu = np.mean(log_returns,axis=0)\n",
    "print(\"The Expected Value vector\\n\\n\",mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix\n",
      "\n",
      " [[2.390e-05 2.480e-05 1.910e-05 1.830e-05 3.740e-05]\n",
      " [2.480e-05 3.170e-05 2.340e-05 2.250e-05 4.670e-05]\n",
      " [1.910e-05 2.340e-05 2.920e-05 2.030e-05 4.050e-05]\n",
      " [1.830e-05 2.250e-05 2.030e-05 3.790e-05 4.080e-05]\n",
      " [3.740e-05 4.670e-05 4.050e-05 4.080e-05 1.404e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the covariance matrix\n",
    "Sigma = np.round(np.cov(log_returns.T),7)\n",
    "print(\"Covariance Matrix\\n\\n\",np.round(Sigma[:7,:7],7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
